# AI-Assisted Generation of Software Bills of Materials for Python Projects

This is a dedicated online replication package for the semester project "AI-Assisted Generation of Software Bills of Materials for Python Projects". Specifically, this repository contains the Python files and Jupyter Notebooks related to fine-tuning and inference for the Llama 2 and Code Llama models. It also contains the files for evaluating the inference results from these models as well as the results for Syft and ChatGPT generated SBOMs. Note that the datatsets used in this work are available upon request. 

## nbs/evaluation/base_models
This directory contains notebooks related to the evaluation of the non-fine-tuned version of Llama 2 and CodeLlama. Each notebook imports the model inference data and checks for JSON content.

## nbs/evaluation/codellama
This directory contains the notebooks related to the evaluation of the fine-tuned Code Llama model. 

## nbs/evaluation/llama2
This directory contains the notebooks related to the evaluation of the fine-tuned Llama 2 model.

## nbs/evaluation/dataset_eval
This directory contains notebooks related to the evaluation of the datasets used in the project. 

testset_data_eval_baseline_repo_select.ipynb breaks down the length of full prompts and inference prompts for the test dataset. It also records the relevant metrics of the test dataset by number of repositories. It also randomly selects the 25 repositories to be used in the ChatGPT evaluation.

valid_req_and_sbom_analysis.ipynb checks the datasets for the number of invalid SBOMs and requirements.txt files. Invalid SBOMs were defined as SBOMs with only one package (primary package), and invalid requirements.txt files were defined as repositories with zero dependencies.

## nbs/evaluation/syft_and_chatgpt
This directory contains files related to the evaluation of the models and tools on the Syft and ChatGPT subsets of data. 

chatgpt_syft_eval.ipynb contains an evaluation of the SBOMs generated by Syft and ChatGPT. 

clone_entire_testset.py was used to programmatically clone the repositories for the test dataset. 

gpt_codellama.ipynb and gpt_llama2.ipynb contain evaluations of the fine-tuned models on the ChatGPT subset of data. 

install_dependents_entire_testset.py was used to programmatically set up and install python virtual environments, which contains the repository dependencies and associated data. 

large_syft_eval.ipynb contains an evaluation of the Syft generated SBOMs. 

syft_codellama.ipynb and syft_llama2.ipynb contain evaluations of the fine-tuned models on the Syft subset of data. 

## nbs/model
This directory contains the notebooks related to the Llama 2 and Code Llama fine-tuning and inference processes. 

codellama_fine_tune.ipynb and llama2_fine_tune.ipynb contain the logic behind the fine-tuning of the LLM models. 

codellama_inference.ipynb and llama2_inference.ipynb contain the model inference procedures. 

Each of the files between the models is very similar. Since Code Llama and Llama 2 are members of the same LLM family, basically all of the code could be reused between the models. 
